# Llama Stack Server Container
# Multi-stage build for smaller, more secure image
# Configuration uses ${env.VAR} syntax - resolved at runtime by Llama Stack

# =============================================================================
# BUILDER STAGE
# =============================================================================
FROM registry.access.redhat.com/ubi9/python-312:9.7@sha256:92c71d1e64cf84b9aa6e8e81555397175b9367298b456d24eac5b55ab41fdab9 AS builder

USER root

ENV UV_COMPILE_BYTECODE=0 \
    UV_LINK_MODE=copy

WORKDIR /app-root

# Install build dependencies
RUN dnf install -y gcc python3-devel make && \
    dnf clean all && \
    pip3.12 install uv

# Copy Llama Stack specific dependency specification
COPY ./pyproject.llama-stack.toml ./pyproject.toml

# Install Python dependencies
RUN uv sync --no-dev

# =============================================================================
# RUNTIME STAGE
# =============================================================================
FROM registry.access.redhat.com/ubi9/python-312-minimal:9.7@sha256:2ac60c655288a88ec55df5e2154b9654629491e3c58b5c54450fb3d27a575cb6

ARG APP_ROOT=/app-root
WORKDIR /app-root

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONCOERCECLOCALE=0 \
    PYTHONUTF8=1 \
    PYTHONIOENCODING=UTF-8 \
    LANG=en_US.UTF-8 \
    PATH="/app-root/.venv/bin:$PATH"

# Copy virtual environment from builder
COPY --from=builder --chown=1001:1001 /app-root/.venv ./.venv

# Copy Llama Stack configuration
# Uses ${env.VAR} syntax - resolved at runtime
COPY --chown=1001:1001 ./run.yaml ./

# Create data directories for runtime
USER root
RUN mkdir -p /data /data/files && \
    chgrp -R 0 /data /app-root && \
    chmod -R g=u /data /app-root

# License
RUN mkdir -p /licenses
COPY LICENSE /licenses/

# Expose Llama Stack server port
EXPOSE 8321

USER 1001

# Default command - run.yaml is in /app-root
CMD ["llama", "stack", "run", "/app-root/run.yaml"]

# Labels
LABEL com.redhat.component=llama-stack-agentic \
      description="Llama Stack Agentic AI Server" \
      io.k8s.description="Llama Stack Agentic AI Server" \
      io.k8s.display-name="Llama Stack Agentic" \
      io.openshift.tags="ai,llama-stack,inference,agents" \
      name=llama-stack-agentic \
      summary="Llama Stack server for agentic AI workflows"
